{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Python notebook on basic linear control: negative feedback loops, feedforward terms, PID control, LQR and basic Lyapunov analysis. -->\n",
    "\n",
    "# Robot control systems\n",
    "\n",
    "Robots are equipped with various actuators that receive inputs and sensors that provide outputs. A robot's brain (its computer) faces the task of deciding what signals to send to the actuators based on the measured sensor readings such that a robot executes desired behavior. This task of controlling the robot must address various challenges such as measurement noise, inaccurate robot models, non-ideal actuators and  external disturbances. Control theory offers a systematic approach to address this challenge by designing control systems to manage robot behavior. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./media/system.png\" alt=\"A system\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A robot can be modelled as a _system_ taking inputs $u(t)$ and producing outputs $y(t)$, such that $y(t) = h(u(t))$. \n",
    "\n",
    "Let us start with a simple, yet widely-applicable class of systmes, namely a discrete-time linear time invariant (LTI) system. It can be expressed the the so-called state-space form as follows\n",
    "\n",
    "$x_{k+1} = Ax_k + Bu_k$,\n",
    "\n",
    "and the output is also given by a linear equation\n",
    "\n",
    "$y_k = Cx_k + Du_k$.\n",
    "\n",
    "The matrix $D = 0$ most often in practice. The system is called linear because the input-output relationship is affine, and time-invariant because the dynamics parameters $A, B, C$, and $D$ are assumed to not depend on time.\n",
    "\n",
    "#### Exercise 3.1: \n",
    "\n",
    "Consider a point-mass object of mass $m$ is free to move along x-axis. The only force acting on it is the external force $f$ in the x-direction. \n",
    "\n",
    "$m\\ddot{x} = f$\n",
    "\n",
    "Consider the position and velocity of the object as the states and the $f$ as the control input, x-position as the output. Use forward Euler integration scheme with timestep $T_s$ for discretizing the system. Provide the $A,B,C,$ and $D$ matrices associated with this system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: $A = \\begin{bmatrix} 1 & T_s \\\\ 0 & 1 \\end{bmatrix} $, $B = \\begin{bmatrix} 0 \\\\ \\frac{T_s}{m} \\end{bmatrix}$, $C = \\begin{bmatrix} 1 & 0 \\end{bmatrix}$ and $D = \\begin{bmatrix} 0 \\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory tracking\n",
    "\n",
    "Consider the trajectory-tracking task, where the system should controlled such that its output follows a desired trajectory $[y_{\\mathrm{des},0}, y_{\\mathrm{des},1}, y_{\\mathrm{des},2}, y_{\\mathrm{des},3}, ... ]$. One of the simplest controllers that can try to execute this task is an `open-loop' feedforward controller shown below.\n",
    "\n",
    "<img src=\"./media/FF.png\" alt=\"Feedforward control system\" width=\"500\"/>\n",
    "\n",
    "Here, the feedforward controller computes the appropriate control input to apply depending on the desired system output. It uses knowledge of the starting state of the system and inverts the system dynamics to compute the trajectory of control inputs to be applied. For example, for a system at state $x_k$ the linear equation below can be solved for $u_k$ to compute the feedforward control action for trajectory following. \n",
    "\n",
    "$y_{\\mathrm{des},k+1} = C(Ax_k + Bu_k) + Du_k$.\n",
    "\n",
    "Pros of pure feedforward control: \n",
    "- FF control systems are simple.\n",
    "- No sensing and estimation are required.\n",
    "- Can follow complex desired trajectories.\n",
    "\n",
    "Cons of pure feedforward control:\n",
    "- Rarely works in practice.\n",
    "- Sensitive to initial state estimation error and model errors.\n",
    "- Inverting system dynamics may not always be possible.\n",
    "\n",
    "### Exercise 3.2:\n",
    "For the point mass system derived in exercise 3.1 and the desired x-positions given below, compute the feedforward control actions. (Hint: Dynamics not directly invertible for tracking position, try tracking the velocity.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinocchio as pin\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy.linalg import inv,norm,pinv,svd,eig\n",
    "from scipy.optimize import fmin_bfgs,fmin_slsqp\n",
    "from scipy.linalg import solve_discrete_are\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "# track a sine function\n",
    "frequency = 2\n",
    "Ts = 0.01\n",
    "m = 1\n",
    "\n",
    "y_des = np.array([np.sin(2*np.pi*frequency*i*Ts) for i in range(200)])\n",
    "\n",
    "# define an LTI system class\n",
    "class LTI_system:\n",
    "    def __init__(self,A,B,C=None,D=None):\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        if C is None:\n",
    "            self.C = np.eye(A.shape)\n",
    "        else:\n",
    "            self.C = C\n",
    "        if D is None:\n",
    "            self.D = np.zeros((C.shape[0],B.shape[1]))\n",
    "        else:\n",
    "            self.D = D\n",
    "        \n",
    "    def step(self,x,u):\n",
    "        return self.A @ x + self.B @ u\n",
    "    \n",
    "    def output(self,x,u):\n",
    "        return self.C @ x + self.D @ u\n",
    "    \n",
    "    def simulate(self,x0,u_traj):\n",
    "        x_step = self.step(x0,u_traj)\n",
    "        y_step = self.output(x0,u_traj)\n",
    "        return x_step, y_step\n",
    "\n",
    "u_traj_ff = []\n",
    "y_traj = []\n",
    "x_traj = []\n",
    "x0 = np.zeros((2,))\n",
    "\n",
    "x_traj.append(x0)\n",
    "\n",
    "\n",
    "\n",
    "## Your code goes below\n",
    "## Use the LTI class above to initialize point-mass system from Ex 3.1, compute the feedforward actions and simulate the system. \n",
    "\n",
    "# Compute desired velocities using FD\n",
    "v_des = np.array([(y_des[i+1] - y_des[i])/Ts for i in range(199)])\n",
    "v_des = np.append(v_des, v_des[-1]) # Use backward FD for last value\n",
    "\n",
    "# Compute feedforward control actions from desired velocities using FD\n",
    "a_des = np.array([(v_des[i+1] - v_des[i])/Ts for i in range(199)])\n",
    "a_des = np.append(a_des, a_des[-1]) # Use backward FD for last value\n",
    "u_traj_ff = m*a_des\n",
    "\n",
    "# You can also compute feedforward actions using analytical derivatives instead of finite differences. This is also accepted.\n",
    "\n",
    "A = np.array([[1 , Ts], [0, 1]])\n",
    "B = np.array([[0], [Ts/m]])\n",
    "C = np.array([[1, 0]])\n",
    "D = np.array([[0]])\n",
    "\n",
    "sys = LTI_system(A,B,C,D)\n",
    "\n",
    "# Part below is optional, not required by the assignment\n",
    "\n",
    "match_initial_conditions = False # Set this to True to also see how feedforward is sensitive to initial conditions. \n",
    "\n",
    "if match_initial_conditions:\n",
    "    x0[1] = (y_des[1] - y_des[0])/Ts # Note: initial condition for velocity should have been set to match the sine function. But the released assignment missed this line. So to get accurate tracking, one option could have been to set solve for the first two control inputs to get correct states after two time-steps. But this is not strictly required for the assignment.\n",
    "else:\n",
    "    # One systematic approach to compute the feedforward is to consider the `controllability matrix' of the system to find actions that will drive the system to the desired trajectory.\n",
    "    #x[2] = A*A*x[0] + A*B*u[0] + B*u[1] \n",
    "    #[u[0], u[1]] = inv(np.hcat[A*B, B]) * (x[2] - A*A*x[0]) \n",
    "    # x0 = [0, 0] as stated in the code. Setting x[2] to desired trajectory gives x[2] = [y_des[2], v_des[2]] \n",
    "\n",
    "    controllability_matrix = np.hstack((sys.A @ sys.B, B))\n",
    "    u_12 = np.linalg.inv(controllability_matrix) @ (np.array([y_des[2], v_des[2]]) -A @ A @ x0)\n",
    "\n",
    "    # You could have considered the initial conditions some other way to compute the feedforward. If you have not, you will find that simulating with the feedforward will cause the trajectory to drift. This is okay. It would also illustrate the sensitivity of pure feedforward control to initial conditions.\n",
    "    u_traj_ff[0] = u_12[0]\n",
    "    u_traj_ff[1] = u_12[1]\n",
    "\n",
    "# You might have used A,B,C,D matrices to compute the feedforward signals. This is also accepted.\n",
    "\n",
    "print(u_12) # You will find the computed feedforward actions here to result in large control inputs, that will likely exceed the actuator limits. Requiring the state to exactly match the desired trajectory directly after two time steps is often too stringent a requirement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot control actions\n",
    "plt.figure()\n",
    "plt.plot(u_traj_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = C@x_traj[-1] + D@u_ff\n",
    "# x_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_des)):\n",
    "    x_step, y_step = sys.simulate(x_traj[-1], np.array([u_traj_ff[i]]))\n",
    "    x_traj.append(x_step)\n",
    "    y_traj.append(y_step)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the simulated trajectory and the desired trajectory\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_des)\n",
    "plt.plot(y_traj)\n",
    "plt.legend(['desired','simulated'])\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('position (m)') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3: \n",
    "Suppose that the mass of the system is not exactly known and that the true mass is 0.9 times the previous mass. Create a new system with this true mass and compute y_traj_real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "y_traj_real = []\n",
    "\n",
    "m_new = 0.9\n",
    "B_new = np.array([[0], [Ts/m_new]])\n",
    "sys_new = LTI_system(A,B_new,C,D)\n",
    "\n",
    "x_traj_real = []\n",
    "x_traj_real.append(x0)\n",
    "y_traj_real = []    \n",
    "\n",
    "for i in range(len(y_des)):\n",
    "    x_step, y_step = sys_new.simulate(x_traj_real[-1], np.array([u_traj_ff[i]]))\n",
    "    \n",
    "    x_traj_real.append(x_step)\n",
    "    y_traj_real.append(y_step)\n",
    "\n",
    "plt.figure\n",
    "plt.plot(y_des)\n",
    "plt.plot(y_traj_real)\n",
    "plt.plot(y_traj)\n",
    "plt.legend(['desired','real','feedforward'])\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('y (m)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Feedback control\n",
    "\n",
    "It is clear from the previous plot that the feedforward control is not enough to track the desired trajectory in the presence of noise, model errors and disturbances. We need a negative feedback loop that measures the error between the desired trajectory and the real trajectory and uses it to reduce tracking errors. Negative feedback loops, being widely and frequently used, are nearly synonymous with the field of control.\n",
    "\n",
    "<img src=\"./media/FB.png\" alt=\"Feedback control system\" width=\"500\"/>\n",
    "\n",
    "For LTI systems, a common form of negative feedback is the linear state feedback law \n",
    "\n",
    "$u = K (x_\\mathrm{des} - x)$.\n",
    "\n",
    "If the control task involves taking the system to the origin ($x_\\mathrm{des} = 0$), the closed-loop system is then described by the following discrete-time LTI system:\n",
    "\n",
    "$x_{k+1} = (A - BK)x_k$\n",
    "\n",
    "$y_k = Cx_k$\n",
    "\n",
    "Typically, state estimators (e.g., [Kalman Filter](https://en.wikipedia.org/wiki/Kalman_filter)) are used to estimate the value of $x_k$ from past sensor readings $y_0, \\dots, y_{k}$, to be able to apply state-feedback. However, for the rest of this assignment, let us assume that the state of our given system is directly measured, meaning that $C = I_{2\\times 2}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise 3.4\n",
    "For the point-mass system, design a state feedback controller for tracking the desired trajectory. Use zero for the desired velocity. (Hint: The design involves guessing the matrix K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_traj_fb = []\n",
    "x_traj_fb = []\n",
    "x_traj_fb.append(x0)\n",
    "\n",
    "y_des.shape\n",
    "x_des = np.vstack([y_des,y_des*0]) # Note that desiring zero velocity for the point-mass is inconsistent with it executing a sinusoidal motion. The ensuing controller with this design choice would be a 'regulator' and not a tracking controller. Typical examples of regulators in real life are cruise control in cars, or thermo-regulation in a room. Attempting to track a sinusoidal trajectory with a regulator would result in a non-zero steady state error and is an educational exercise in tuning and understanding the limitations of regulators.\n",
    "#Setting x_des as below would have been a better choice for tracking a sinusoidal trajectory. You will be able to use smaller gains that are less likely to saturate actuators. Try it out to see how much better the controller behaves. In your future robotics projects, if you have a PD controller do not forget to send reference velocities to the controller. Tracking higher derivatives of the desired position reference is key for high performance tracking.\n",
    "# x_des = np.vstack([y_des,v_des]) # with this choice, the controller gains can be lower.\n",
    "\n",
    "K = np.array([[5000.0, 100.0]]) # But these gains are quite high\n",
    "\n",
    "u_traj_fb = []\n",
    "\n",
    "for i in range(200):\n",
    "\n",
    "    # pass\n",
    "    x_err = x_des[:,i] - x_traj_fb[-1]\n",
    "    u = K @ x_err\n",
    "    u_traj_fb.append(u)\n",
    "    x_step, y_step = sys.simulate(x_traj_fb[-1], u)\n",
    "    x_traj_fb.append(x_step)\n",
    "    y_traj_fb.append(y_step[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot state tracking\n",
    "plt.figure()\n",
    "plt.plot(y_des)\n",
    "plt.plot(y_traj_fb)\n",
    "plt.legend(['desired','simulated'])\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('position (m)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot control actions\n",
    "plt.figure()\n",
    "plt.plot(u_traj_fb)\n",
    "plt.plot(u_traj_ff)\n",
    "plt.legend(['feedback','feedforward'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.5\n",
    "Suppose that the system also has noisy dynamics. Add Gaussian noise to the x_step output of the LTI system. Simulate the system you designed in Ex 3.4. What can you say about its behavior and how the magnitude of $K$ affects tracking in noisy systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_traj_fb = []\n",
    "x_traj_fb = []\n",
    "x_traj_fb.append(x0)\n",
    "\n",
    "# K = np.array([[5000.0, 100]]) # But these gains are quite high\n",
    "\n",
    "u_traj_fb = []\n",
    "\n",
    "for i in range(200):\n",
    "\n",
    "    # pass\n",
    "    x_err = x_des[:,i] - x_traj_fb[-1]\n",
    "    u = K @ x_err\n",
    "    u_traj_fb.append(u)\n",
    "    x_step, y_step = sys.simulate(x_traj_fb[-1], u)\n",
    "    x_step += np.random.normal(0, 0.02, x_step.shape)\n",
    "    x_traj_fb.append(x_step)\n",
    "    y_traj_fb.append(y_step[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot state tracking\n",
    "plt.figure()\n",
    "plt.plot(y_des)\n",
    "plt.plot(y_traj_fb)\n",
    "plt.legend(['desired','simulated'])\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('position (m)') # Disturbance rejection is quite good since high gains are used.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot control actions\n",
    "plt.figure()\n",
    "plt.plot(u_traj_fb)\n",
    "plt.legend(['feedback']) # Because high control gains were chosen to reduce tracking error, the influence of the measurement noise on control actions is quite significant. Typically actuators cannot provide such noisy control actions and it might even be unsafe to send this control signal. It is a common trade-off in control design between tracking performance and robustness to noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Superior tracking often requires both feedforward and feedback control as shown in \n",
    "\n",
    "<img src=\"./media/FF_FB.png\" alt=\"Feedback control system\" width=\"700\"/>\n",
    "\n",
    "Feedforward terms permit tracking complex trajectories using the knowledge of system dynamics while the feedback terms stabilize the system around the desired setpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.6\n",
    "Combine the feedback and feedforward actions to track the desired trajectory for the point mass system from Exercise 3.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_traj_fbff = []\n",
    "x_traj_fbff = []\n",
    "u_traj_fb = []\n",
    "u_traj = []\n",
    "x_traj_fbff.append(x0)\n",
    "\n",
    "for i in range(200):\n",
    "    x_err = x_des[:,i] - x_traj_fbff[i]  \n",
    "    u = K @ x_err + u_traj_ff[i]\n",
    "    u_traj_fb.append(K @ x_err)\n",
    "    u_traj.append(u)\n",
    "    x_step, _ = sys_new.simulate(x_traj_fbff[-1], u_traj[-1])\n",
    "    x_traj_fbff.append(x_step)\n",
    "    y_traj_fbff.append(sys_new.output(x_step, u_traj[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the simulated trajectory and the desired trajectory\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_des)\n",
    "plt.plot(y_traj_real)\n",
    "plt.plot(y_traj_fbff)\n",
    "plt.legend(['desired','feedforward','feedback+feedforward'])\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('position (m)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot control actions\n",
    "plt.figure()\n",
    "plt.plot(u_traj_fb)\n",
    "plt.plot(u_traj_ff)\n",
    "plt.legend(['feedback','feedforward']) # Feedforward is doing most of the work, feedback is just correcting for the tracking error due to the model mismatch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System stability\n",
    "\n",
    "You perhaps encountered system instability (where the trajectories keep growing in magnitude) and are curious if there is a systematic approach to define and check for this phenomenon.\n",
    "\n",
    "Let us consider regulation problem, where the desired trajectory being tracked is a fixed set-point. Without loss of generality (why?) for regulation problems, we can assume that we want the system to reach the origin. A system \n",
    "\n",
    "$x_{k+1} = A x_k$,\n",
    "\n",
    "is said to be asymptotically stable if $\\lim_{k \\to \\infty} x_k = 0$. For an LTI system, checking for stability amounts to checking if the magnitude of all the eigenvalues of the matrix $A$ is strictly less than 1.0. Then the system is said to be strictly stable. If one eigenvalue has a magnitude equal to 1, the system is said to be marginally stable. If more than one eigenvalue has a magnitude equal to 1, the system may be unstable. If even one eigenvalue magnitude is strictly greater than one, the system is unstable.\n",
    "\n",
    "Note that a closed loop LTI system is given by\n",
    "\n",
    "$x_{k+1} = A_\\mathrm{cl} x_k$,\n",
    "\n",
    "where $A_\\mathrm{cl} = A - B K$. Therefore, stability of the closed-loop LTI systems is characterized using the eigenvalues of the matrix $A_\\mathrm{cl}$. \n",
    "\n",
    "It is important to characterize the stability of the feedback system, as it is a property that implies 'good behavior' of the closed-loop system, i.e. that it will not diverge or oscillate from the desired set-point.  Unstable systems can be dangerous in practice. \n",
    "\n",
    "\n",
    "### Exercise 3.7 \n",
    "\n",
    "Compute the eigenvalues of the point-mass system and of the closed-loop system with the linear feedback gains chosen in Exercise 3.4. Characterize the stability property of these two systems.\n",
    "\n",
    "Answer: Enter your answer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_cl = A - B @ K\n",
    "eigvals, eigvecs = eig(A_cl)\n",
    "print(eigvals)\n",
    "\n",
    "# compute the magnitude of the eigenvalues\n",
    "eigvals_mag = np.abs(eigvals)\n",
    "print(eigvals_mag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the magnitudes of both the eigenvalues are strictly below one, the closed-loop system for the hand-tuned control gains is stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it was fairly straightforward to guess stable feedback gains for the point mass system, this is not so easy for more complex systems with higher dimensions. Fortunately, there exist several methods to compute these gains. One of the most popular methods is Linear Quadratic Regulator (LQR). LQR is a method that minimizes the cost function, (assuming that the system is being stabilized around the origin):\n",
    "\n",
    "$J = \\sum_{t=0}^{T} (x_t^T Q x_t + u_t^T R u_t)$,\n",
    "where $Q$ and $R$ are positive definite matrices. The LQR controller is the optimal feedback gain that minimizes this cost function. The LQR controller can be computed using the following steps:\n",
    "\n",
    " 1. Solve the discrete-time Riccati equation for the system:\n",
    " \n",
    "    $ P = A^T P A - A^T P B (B^T P B + R)^{-1} B^T P A + Q $ \n",
    "\n",
    "2. Compute feedback gain\n",
    "\n",
    "    $K = (R + B^T P B)^{-1} B^T P A$\n",
    "\n",
    "3. The control law is then:\n",
    "    \n",
    "    $ u = -K x $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LQR (and linear control in general) is a useful tool even for controlling nonlinear systems. Nonlinear systems are often locally linearizable, using their first derivatives. The controller design is then performed for this linearized system and can be effective as long as the nonlinear system remains close to the linearization point.\n",
    "\n",
    "In this exercise, we will consider the nonlinear system cart-pole, linearized around the upright position. The state of the system is \n",
    "\n",
    "$x = \\begin{bmatrix} x \\\\ \\theta \\\\ \\dot{x} \\\\ \\dot{\\theta} \\end{bmatrix}$.\n",
    "\n",
    "The system dynamics and the linearization around the upright position can be found in \n",
    "https://courses.ece.ucsb.edu/ECE594/594D_W10Byl/hw/cartpole_eom.pdf\n",
    "\n",
    "Assume that $M = 1$, $m_p = 1$ and $L = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.8 \n",
    "\n",
    "Compute the LQR feedback gains for the cart-pole system linearized at the upright position. Stabilize the system at the upright position the LQR controller, starting from a state close to the upright position. Simulate the nonlinear system for 10 seconds and plot the state trajectories.\n",
    "\n",
    "(Hint: use scipy.linalg.solve_discrete_are to solve the Riccati equation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 9.81\n",
    "M = 1\n",
    "m = 1\n",
    "l = 1\n",
    "\n",
    "# Define the system matrices\n",
    "A = np.array([[1, Ts, 0, 0], [0, 1, Ts*g, 0], [0, 0, 1, Ts], [0, 0, 2*g*Ts, 1]])\n",
    "B = np.array([[0], [Ts], [0], [Ts]])\n",
    "\n",
    "C = np.array([[0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "D = np.zeros((2,1))\n",
    "\n",
    "# Define the system\n",
    "sys = LTI_system(A,B,C,D)\n",
    "\n",
    "# compute LQR feedback gain\n",
    "Q = np.diag([0.1,0.1,1,1])\n",
    "R = np.diag([1])\n",
    "P = solve_discrete_are(A,B,Q,R)\n",
    "K = inv(R + B.T @ P @ B) @ B.T @ P @ A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nonlinear system, Forward Euler\n",
    "def nls_cartpole(x,u, Ts):\n",
    "    M = 1\n",
    "    m = 1\n",
    "    l = 1\n",
    "    xcdot = x[1]\n",
    "    thetadot = x[3]\n",
    "    xc = x[0]\n",
    "    theta = x[2]\n",
    "    s = np.sin(theta)\n",
    "    c = np.cos(theta)\n",
    "    u = np.clip(u, -5, 5)\n",
    "    xcddot = (-s*(m*l)*c*thetadot**2 + s*m*c*g + u)/(-m*c**2 + M + m)\n",
    "    thetaddot = (-s*(m*l)*c*thetadot**2 + s*g*(M+m) + u*c)/(l*(-m*c**2 + M + m))\n",
    "    xc = xc + Ts*xcdot\n",
    "    xcdot = xcdot + Ts*xcddot\n",
    "    theta = theta + Ts*thetadot\n",
    "    thetadot = thetadot + Ts*thetaddot\n",
    "    return np.hstack([xc,xcdot,theta,thetadot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsteps = 1000\n",
    "# simulate the system\n",
    "x0 = np.array([0,0,0.1,0])\n",
    "x_traj = []\n",
    "x_traj.append(x0)\n",
    "u_traj = []\n",
    "y_traj = []\n",
    "y_traj.append(C @ x0)\n",
    "for i in range(Nsteps):\n",
    "    u = -K @ x_traj[-1]\n",
    "    x_step = nls_cartpole(x_traj[-1],u,Ts)\n",
    "    x_traj.append(x_step)\n",
    "    y_traj.append(C @ x_step)\n",
    "    u_traj.append(u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot the simulated trajectory and the desired trajectory\n",
    "plt.figure()\n",
    "plt.plot(np.linspace(0,Nsteps*Ts,Nsteps+1),[y[0] for y in y_traj])\n",
    "plt.plot(np.linspace(0,Nsteps*Ts,Nsteps+1),[y[1] for y in y_traj])\n",
    "plt.legend(['$\\\\theta$','$\\\\dot{\\\\theta}$'])\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('position (m)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot the control input\n",
    "plt.figure()\n",
    "plt.plot(np.linspace(0,Nsteps*Ts,Nsteps),u_traj)\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('control input')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
