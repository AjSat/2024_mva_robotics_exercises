{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Python notebook on basic linear control: negative feedback loops, feedforward terms, PID control, LQR and basic Lyapunov analysis. -->\n",
    "\n",
    "# Robot control systems\n",
    "\n",
    "Robots are equipped with various actuators that receive inputs and sensors that provide outputs. A robot's brain (its computer) faces the task of deciding what signals to send to the actuators based on the measured sensor readings such that a robot executes desired behavior. This task of controlling the robot must address various challenges such as measurement noise, inaccurate robot models, non-ideal actuators and  external disturbances. Control theory offers a systematic approach to address this challenge by designing control systems to manage robot behavior. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tp3/media/system.png\" alt=\"A system\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A robot can be modelled as a _system_ taking inputs $u(t)$ and producing outputs $y(t)$, such that $y(t) = h(u(t))$. \n",
    "\n",
    "Let us start with a simple, yet widely-applicable class of systmes, namely a discrete-time linear time invariant (LTI) system. It can be expressed the the so-called state-space form as follows\n",
    "\n",
    "$x_{k+1} = Ax_k + Bu_k$,\n",
    "\n",
    "and the output is also given by a linear equation\n",
    "\n",
    "$y_k = Cx_k + Du_k$.\n",
    "\n",
    "The matrix $D = 0$ most often in practice. The system is called linear because the system dynamics is linear in $x$ and $u$, the input-output relationship is affine, and time-invariant because the dynamics parameters $A, B, C$, and $D$ are assumed to not depend on time.\n",
    "\n",
    "#### Exercise 3.1: \n",
    "\n",
    "Consider a point-mass object of mass $m$ is free to move along x-axis. The only force acting on it is the external force $f$ in the x-direction. \n",
    "\n",
    "$m\\ddot{x} = f$\n",
    "\n",
    "Consider the position and velocity of the object as the states and the $f$ as the control input, x-position as the output. Use forward Euler integration scheme with timestep $T_s$ for discretizing the system. Provide the $A,B,C,$ and $D$ matrices associated with this system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Add here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory tracking\n",
    "\n",
    "Consider the trajectory-tracking task, where the system should controlled such that its output follows a desired trajectory $[y_{\\mathrm{des},0}, y_{\\mathrm{des},1}, y_{\\mathrm{des},2}, y_{\\mathrm{des},3}, ... ]$. One of the simplest controllers that can try to execute this task is an `open-loop' feedforward controller shown below.\n",
    "\n",
    "<img src=\"tp3/media/FF.png\" alt=\"Feedforward control system\" width=\"500\"/>\n",
    "\n",
    "Here, the feedforward controller computes the appropriate control input to apply depending on the desired system output. It uses knowledge of the starting state of the system and inverts the system dynamics to compute the trajectory of control inputs to be applied. For example, for a system at state $x_k$ the linear equation below can be solved for $u_k$ to compute the feedforward control action for trajectory following. \n",
    "\n",
    "$y_{\\mathrm{des},k+1} = C(Ax_k + Bu_k) + Du_k$.\n",
    "\n",
    "Pros of pure feedforward control: \n",
    "- FF control systems are simple.\n",
    "- No sensing and estimation are required.\n",
    "- Can follow complex desired trajectories.\n",
    "\n",
    "Cons of pure feedforward control:\n",
    "- Rarely works in practice.\n",
    "- Sensitive to initial state estimation error and model errors.\n",
    "- Inverting system dynamics may not always be possible.\n",
    "\n",
    "### Exercise 3.2:\n",
    "For the point mass system derived in exercise 3.1 and the desired x-positions given below, compute the feedforward control actions. (Hint: Dynamics not directly invertible for tracking position, try tracking the velocity.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinocchio as pin\n",
    "from utils.meshcat_viewer_wrapper import MeshcatVisualizer\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy.linalg import inv,norm,pinv,svd,eig\n",
    "from scipy.optimize import fmin_bfgs,fmin_slsqp\n",
    "from scipy.linalg import solve_discrete_are\n",
    "from utils.load_ur5_with_obstacles import load_ur5_with_obstacles,Target\n",
    "import example_robot_data as robex\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "# track a sine function\n",
    "frequency = 2\n",
    "Ts = 0.01\n",
    "m = 1\n",
    "\n",
    "y_des = np.array([np.sin(2*np.pi*frequency*i*Ts) for i in range(200)])\n",
    "\n",
    "# define an LTI system class\n",
    "class LTI_system:\n",
    "    def __init__(self,A,B,C=None,D=None):\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        if C is None:\n",
    "            self.C = np.eye(A.shape)\n",
    "        else:\n",
    "            self.C = C\n",
    "        if D is None:\n",
    "            self.D = np.zeros((C.shape[0],B.shape[1]))\n",
    "        else:\n",
    "            self.D = D\n",
    "        \n",
    "    def step(self,x,u):\n",
    "        return self.A @ x + self.B @ u\n",
    "    \n",
    "    def output(self,x,u):\n",
    "        return self.C @ x + self.D @ u\n",
    "    \n",
    "    def simulate(self,x0,u_traj):\n",
    "        x_step = self.step(x0,u_traj)\n",
    "        y_step = self.output(x0,u_traj)\n",
    "        return x_step, y_step\n",
    "\n",
    "u_traj_ff = []\n",
    "y_traj = []\n",
    "x_traj = []\n",
    "x0 = np.zeros((2,))\n",
    "x_traj.append(x0)\n",
    "\n",
    "## Your code goes below\n",
    "## Use the LTI class above to initialize point-mass system from Ex 3.1, compute the feedforward actions and simulate the system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the simulated trajectory and the desired trajectory\n",
    "plt.figure()\n",
    "plt.plot(y_des)\n",
    "plt.plot(y_traj)\n",
    "plt.legend(['desired','simulated'])\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('position (m)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3: \n",
    "Suppose that the mass of the system is not exactly known and that the true mass is 0.9 times the previous mass. Create a new system with this true mass and compute y_traj_real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_traj_real = []\n",
    "m_new = 0.9\n",
    "\n",
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(y_des)\n",
    "plt.plot(y_traj_real)\n",
    "plt.plot(y_traj)\n",
    "plt.legend(['desired','real','feedforward'])\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('y (m)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback control\n",
    "\n",
    "It is clear from the previous plot that the feedforward control is not enough to track the desired trajectory in the presence of noise, model errors and disturbances. We need a negative feedback loop that measures the error between the desired trajectory and the real trajectory and uses it to reduce tracking errors. Negative feedback loops, being widely and frequently used, are nearly synonymous with the field of control.\n",
    "\n",
    "<img src=\"tp3/media/FB.png\" alt=\"Feedback control system\" width=\"500\"/>\n",
    "\n",
    "For LTI systems, a common form of negative feedback is the linear state feedback law \n",
    "\n",
    "$u = K (x_\\mathrm{des} - x)$.\n",
    "\n",
    "If the control task involves taking the system to the origin ($x_\\mathrm{des} = 0$),the closed-loop system is then described by the following discrete-time LTI system:\n",
    "\n",
    "$x_{k+1} = (A - BK)x_k$\n",
    "\n",
    "$y_k = Cx_k$\n",
    "\n",
    "### Exercise 3.4\n",
    "For the point-mass system, design a state feedback controller for tracking the desired trajectory. Use zero for the desired velocity. (Hint: The design involves guessing the matrix K.)\n",
    "\n",
    "Additional info: We are implementing a proportional-derivative (PD) controller. The first term of K acting on the position error, is the proportional controller gain, while the second term of K, acting on the velocity error, is the derivative error controller gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_des.shape\n",
    "x_des = np.vstack([y_des,y_des*0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_traj_fb = []\n",
    "x_traj_fb = []\n",
    "x_traj_fb.append(x0)\n",
    "\n",
    "x_des = np.vstack([y_des,y_des*0])\n",
    "\n",
    "K = np.array([[]]) # Add your feedback gains here\n",
    "\n",
    "u_traj_fb = []\n",
    "\n",
    "for i in range(200):\n",
    "\n",
    "    pass\n",
    "    # Add your code here\n",
    "    # u = ?\n",
    "    u_traj_fb.append(u)\n",
    "    # x_step, y_step = sys.simulate(x_traj_fb[-1], u)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot state tracking\n",
    "plt.figure()\n",
    "plt.plot(y_des)\n",
    "plt.plot(y_traj_fb)\n",
    "plt.legend(['desired','simulated'])\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('position (m)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.5\n",
    "Suppose that the system also has noisy dynamics. Add Gaussian noise to the x_step output of the LTI system. Simulate the system you designed in Ex 3.4. What can you say about its behavior and how the magnitude of $K$ affects tracking in noisy systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Superior tracking often requires both feedforward and feedback control as shown in \n",
    "\n",
    "<img src=\"tp3/media/FF_FB.png\" alt=\"Feedback control system\" width=\"700\"/>\n",
    "\n",
    "Feedforward terms permit tracking complex trajectories using the knowledge of system dynamics while the feedback terms stabilize the system around the desired setpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.6\n",
    "Combine the feedback and feedforward actions to track the desired trajectory for the point mass system from Exercise 3.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_traj_fbff = []\n",
    "x_traj_fbff = []\n",
    "u_traj = []\n",
    "x_traj_fbff.append(x0)\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the simulated trajectory and the desired trajectory\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_des)\n",
    "plt.plot(y_traj_fbff)\n",
    "plt.legend(['desired','simulated'])\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('position (m)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System stability\n",
    "\n",
    "Let us consider regulation problem, where the desired trajectory being tracked is a fixed set-point. Without loss of generality (why?) for regulation problems, we can assume that we want the system to reach the origin. \n",
    "\n",
    "It is important to characterize the stability of the feedback system, as it is a property that implies 'good behavior' of the closed-loop system, i.e. that it will not diverge or oscillate from the desired set-point.  Unstable systems can be dangerous in practice. \n",
    "\n",
    "The stability of closed-loop LTI systems can be straightforwardly characterized using the eigenvalues of the closed-loop system matrix $A_\\mathrm{cl} = A - B K$. The magnitude of all the eigenvalues of the matrix A - B*K should be less than 1.0. For LTI systems, this is equivalent to checking that the system is strictly stable. If one eigenvalue has a magnitude equal to 1, the system is said to be marginally stable. If more than one eigenvalue has a magnitude equal to 1, the system may be unstable. If even one eigenvalue magnitude is strictly greater than one, the system is unstable. Note that since \n",
    "\n",
    "$x_{k+1} = A_\\mathrm{cl} x_k$,\n",
    "\n",
    "strict stability implies that the state converges to the origin at an exponential rate (exponential rate is not so fast when you are decreasing compared to when you are increasing).\n",
    "\n",
    "### Exercise 3.7 \n",
    "\n",
    "Compute the eigenvalues of the point-mass system and the closed-loop system with the linear feedback gains chosen in Exercise 3.4 and characterize the stability property of these two systems.\n",
    "\n",
    "Answer: Enter your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Quadratic Regulator\n",
    "\n",
    "While it was fairly straightforward to guess stable feedback gains for the point mass system, this is not so easy for more complex systems with higher dimensions. Fortunately, there exist several methods to compute these gains. One of the most popular methods is Linear Quadratic Regulator (LQR). LQR is a method that minimizes the cost function, (assuming that the system is being stabilized around the origin):\n",
    "\n",
    "$J = \\sum_{t=0}^{\\infty} (x_t^T Q x_t + u_t^T R u_t)$,\n",
    "where $Q$ and $R$ are positive definite matrices. The LQR controller is the optimal feedback gain that minimizes this cost function. The LQR controller can be computed using the following steps:\n",
    "\n",
    " 1. Solve the discrete-time Riccati equation for the system:\n",
    " \n",
    "    $ P = A^T P A - A^T P B (B^T P B + R)^{-1} B^T P A + Q $ \n",
    "\n",
    "2. Compute feedback gain\n",
    "\n",
    "    $K = (R + B^T P B)^{-1} B^T P A$\n",
    "\n",
    "3. The control law is then:\n",
    "    \n",
    "    $ u = -K x $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LQR (and linear control in general) is a useful tool even for controlling nonlinear systems. Nonlinear systems are often locally linearizable, using their first derivatives. The controller design is then performed for this linearized system and can be effective as long as the nonlinear system remains close to the linearization point.\n",
    "\n",
    "In this exercise, we will consider the nonlinear system cart-pole, linearized around the upright position. The state of the system is \n",
    "\n",
    "$x = \\begin{bmatrix} x \\\\ \\theta \\\\ \\dot{x} \\\\ \\dot{\\theta} \\end{bmatrix}$.\n",
    "\n",
    "The system dynamics and the linearization around the upright position can be found in \n",
    "https://courses.ece.ucsb.edu/ECE594/594D_W10Byl/hw/cartpole_eom.pdf\n",
    "\n",
    "Assume that $M = 0$, $m_p = 1$ and $L = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.8\n",
    "\n",
    "Compute the LQR feedback gains for the cart-pole system linearized at the upright position. Stabilize the system at the upright position the LQR controller, starting from a state close to the upright position. Simulate the nonlinear system for 10 seconds and plot the state trajectories.\n",
    "\n",
    "(Hint: use scipy.linalg.solve_discrete_are to solve the Riccati equation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus question (coming)\n",
    "\n",
    "Let us setup a robot system that takes joint velocities as inputs and provides EE positions as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Robot:\n",
    "\n",
    "    def __init__(self, robotname, q0, ee_name, Ts = 0.01):\n",
    "        self.robot = robex.load(robotname)\n",
    "        self.x = q0\n",
    "        self.ee_id = self.robot.model.getFrameId(ee_name)\n",
    "        self.Ts = Ts\n",
    "\n",
    "    def fk_ee(self, q = None):\n",
    "        if q is None:\n",
    "            q = self.x\n",
    "        robot = self.robot\n",
    "        pin.framesForwardKinematics(robot.model, robot.data, q)\n",
    "        return self.robot.data.oMf[self.ee_id]\n",
    "    \n",
    "    def apply_input(self, u, noise = 'normal'):\n",
    "        if noise == 'normal':\n",
    "            u += np.random.normal(0, 0.1, 6)*self.Ts\n",
    "        self.x = pin.integrate(self.robot.model, self.x, u*self.Ts)\n",
    "        \n",
    "        return self.fk_ee(self.x)\n",
    "    \n",
    "\n",
    "q0 = np.array([0, -1.5, 1.5, 0, 0, 0])\n",
    "robot = Robot('ur5', q0, 'tool0')\n",
    "\n",
    "viz = MeshcatVisualizer(robot.robot)\n",
    "viz.display(robot.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.fk_ee()\n",
    "# len(robot.robot.data.)\n",
    "# robot.ee_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $$p(t) = \\mathrm{fk_{ee}}(q(t))$$ be the end-effector position at time $t$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
